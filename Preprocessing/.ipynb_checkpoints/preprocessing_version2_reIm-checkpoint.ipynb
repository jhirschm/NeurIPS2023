{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae184a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os\n",
    "from util import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0632e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_arrays(*arrays):\n",
    "    return np.concatenate(arrays, axis=None)\n",
    "\n",
    "def re_im_concat(shg1, shg2, sfg):\n",
    "    vector = concatenate_arrays(np.real(shg1), np.real(shg2), np.real(sfg), np.imag(shg1), np.imag(shg2), np.imag(sfg))\n",
    "    return vector\n",
    "\n",
    "def sample_concat2(directory, output_dir, k=10, n=20, save=True, stop_early=False, stop_early_num = 1):\n",
    "    '''\n",
    "    Concats .npy files in a given directory based on sliding length\n",
    "\n",
    "    Input:\n",
    "    directory: directory of samples\n",
    "    k: int, length of sliding window\n",
    "    n: int, number of files used to train\n",
    "\n",
    "    Output:\n",
    "    save new sample files in some new directory\n",
    "    '''\n",
    "    np.random.seed(42)\n",
    "    fn = os.path.join(directory, \"*.npy\")\n",
    "    files = glob.glob(fn)\n",
    "    np.random.shuffle(files)\n",
    "    i = -1\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    for split in np.array_split(files, n):\n",
    "        i += 1\n",
    "        print(i)\n",
    "        # get all dict\n",
    "        param_path = np.array([i.replace(\".npy\", \".pkl\") for i in split])\n",
    "        np.save(os.path.join(output_dir, f\"param_{i}.npy\"), param_path)\n",
    "        X = []\n",
    "        y = []\n",
    "        for f in split:\n",
    "            arr = np.load(f)\n",
    "            arr = np.array([re_im_concat(temp[:1892], temp[1892:1892 * 2], temp[-348:]) for temp in arr])\n",
    "            scaler.partial_fit(arr.reshape(arr.shape[0], -1))\n",
    "            shape = (k, arr.shape[1])\n",
    "            y.append(arr[1:])\n",
    "            duplicate = np.repeat([arr[0]], k - 1, axis=0)\n",
    "            arr = np.concatenate((duplicate, arr[:-1]), axis=0)\n",
    "            new = np.array([[arr[i:i + k]] for i in range(len(arr) - k + 1)]).reshape(-1, k, arr.shape[1])\n",
    "            X.append(new)\n",
    "\n",
    "        X, y = np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "        if save:\n",
    "            np.save(os.path.join(output_dir, f\"X_{i}.npy\"), X)\n",
    "            np.save(os.path.join(output_dir, f\"y_{i}.npy\"), y)\n",
    "            with open(os.path.join(output_dir, 'scaler.pkl'), 'wb') as file:\n",
    "                pickle.dump(scaler, file)\n",
    "        \n",
    "        if (stop_early and i==stop_early_num):\n",
    "            break\n",
    "\n",
    "    for i in range(n):\n",
    "        X = np.load(os.path.join(output_dir, f\"X_{i}.npy\"))\n",
    "        y = np.load(os.path.join(output_dir, f\"y_{i}.npy\"))\n",
    "        X_new = np.copy(X)\n",
    "        y_new = scaler.transform(y.reshape(y.shape[0], -1))\n",
    "        for jj in range(X.shape[1]):\n",
    "            X_new[:, jj, :] = scaler.transform(X[:, jj, :].reshape(X.shape[0], -1))\n",
    "        if save:\n",
    "            np.save(os.path.join(output_dir, f\"X_new_{i}.npy\"), X_new)\n",
    "            np.save(os.path.join(output_dir, f\"y_new_{i}.npy\"), y_new)\n",
    "\n",
    "        if (stop_early and i==stop_early_num):\n",
    "            break\n",
    "    return X, y, X_new, y_new, scaler, param_path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91cf707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required data and set up vectors and dictionaries (paths may needed to be adjusted based on your operating system, file structure, and from where code is being run)\n",
    "freq_vectors_shg1 = np.load(\n",
    "    \"../Data/shg_freq_domain_ds.npy\")\n",
    "freq_vectors_shg2 = freq_vectors_shg1 # these are equivalent here\n",
    "freq_vectors_sfg = np.load(\n",
    "    \"../Data/sfg_freq_domain_ds.npy\")\n",
    "\n",
    "domain_spacing_1 = (freq_vectors_shg1[1] - freq_vectors_shg1[0]) * 1e12 #scaled to be back in Hz\n",
    "domain_spacing_2 = (freq_vectors_shg2[1] - freq_vectors_shg2[0]) * 1e12\n",
    "domain_spacing_3 = (freq_vectors_sfg[1] - freq_vectors_sfg[0]) * 1e12\n",
    "\n",
    "factors_freq = {\"beam_area\": 400e-6 ** 2 * np.pi,\n",
    "                \"grid_spacing\": [domain_spacing_1, domain_spacing_2, domain_spacing_3],\n",
    "                \"domain_spacing_1\": domain_spacing_1, \"domain_spacing_2\": domain_spacing_2,\n",
    "                \"domain_spacing_3\": domain_spacing_3} #beam radius 400 um (and circular beam)\n",
    "\n",
    "data_directory = \"/sdf/group/lcls/ds/scratch/s2e_scratch/Data/SFG_0504\" #this is where you downloaded data from SDR repo\n",
    "output_dir = \"/sdf/group/lcls/ds/scratch/s2e_scratch/Data/SFG_reIm/test\" #this is where you want to store the reformatted data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f3ee03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1, X1_new, y1_new, scaler1, file1 = sample_concat2(data_directory, output_dir, k=10, n=100, save=True, stop_early = True, stop_early_num=3)\n",
    "with open(os.path.join(output_dir, 'scaler_bckkup.pkl'), 'wb') as file:\n",
    "    pickle.dump(scaler1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4485a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
